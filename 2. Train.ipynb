{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir('../input/efficenet-b4-30-epochs')","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"['model-0000.h5']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/kaggle-efficientnet-repo/efficientnet-1.0.0-py3-none-any.whl","execution_count":3,"outputs":[{"output_type":"stream","text":"Processing /kaggle/input/kaggle-efficientnet-repo/efficientnet-1.0.0-py3-none-any.whl\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from efficientnet==1.0.0) (0.16.2)\nRequirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from efficientnet==1.0.0) (1.0.8)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (2.6.1)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (3.0.3)\nRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (1.4.1)\nRequirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (1.1.1)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (2.4)\nRequirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (5.4.1)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (1.18.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (2.10.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (1.1.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (2.4.6)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (2.8.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0) (4.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (1.14.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (45.2.0.post20200210)\nInstalling collected packages: efficientnet\nSuccessfully installed efficientnet-1.0.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport argparse\nimport pandas as pd\nimport numpy as np\nimport argparse\nimport tensorflow as tf\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\nfrom kaggle_datasets import KaggleDatasets\n\nfrom tensorflow.keras import layers as L\nimport efficientnet.tfkeras as efn\nprint(\"Tensorflow version \" + tf.__version__)","execution_count":4,"outputs":[{"output_type":"stream","text":"Tensorflow version 2.1.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\ndef get_recall(y_true, y_pred):\n    pred_labels = np.argmax(y_pred, axis=1)\n    res = recall_score(y_true, pred_labels, average='macro')\n    return res","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(image):\n    image -= tf.constant([0.485 * 255, 0.456 * 255, 0.406 * 255])\n    image /= tf.constant([0.229 * 255, 0.224 * 255, 0.225 * 255])\n    return image","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(input_size, backbone='efficientnet-b0', weights='imagenet', tta=False):\n    print(f'Using backbone {backbone} and weights {weights}')\n    x = L.Input(shape=input_size, name='imgs', dtype='float32')\n    y = normalize(x)\n    \n    if backbone.startswith('efficientnet'):\n        model_fn = getattr(efn, f'EfficientNetB{backbone[-1]}')\n        \n    y = model_fn(input_shape=input_size, weights=weights, include_top=False)(y)\n    y = L.GlobalAveragePooling2D()(y)\n    y = L.Dropout(0.2)(y)\n    # 1292 out 1295 are present at bottom layer\n    y = L.Dense(1292, activation='softmax')(y)\n    model = tf.keras.Model(x, y)\n    \n    if tta:\n        assert False, 'This doesn not make sense'\n        x_flip = tf.reverse(x, [2])  # 'NHWC'\n        y_tta = tf.add(model(x), model(x_flip)) / 2.0\n        tta_model = tf.keras.Model(x, y_tta)\n        return model, tta_model\n\n    return model","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read mixup paper\ndef mixup(img_batch, label_batch, bs):\n    weight = tf.random.uniform([bs])\n    x_weight = tf.reshape(weight, [bs,1,1,1])\n    y_weight = tf.reshape(weight, [bs,1])\n    index = tf.random.shuffle(tf.range(bs, dtype=tf.int32))\n    x1, x2 = img_batch, tf.gather(img_batch, index)\n    img_batch = x1* x_weight + x2*(1. - x_weight)\n    y1, y2 = label_batch, tf.gather(label_batch, index)\n    label_batch = y1* y_weight + y2*(1. - y_weight)\n    return img_batch, label_batch","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_strategy():\n  # Detect hardware, return appropriate distribution strategy\n  try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n  except ValueError:\n    tpu = None\n\n  if tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n  else:\n    strategy = tf.distribute.get_strategy()\n\n  print('REPLICAS: ', strategy.num_replicas_in_sync)\n  return strategy\n\n\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot(image, label):\n  label = tf.one_hot(label, 1292)\n  return image, label","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_tfrecords(example, input_size):\n  features = {\n      'img': tf.io.FixedLenFeature([], tf.string),\n      'image_id': tf.io.FixedLenFeature([], tf.int64),\n      'grapheme_root': tf.io.FixedLenFeature([], tf.int64),\n      'vowel_diacritic': tf.io.FixedLenFeature([], tf.int64),\n      'consonant_diacritic': tf.io.FixedLenFeature([], tf.int64),\n      'unique_tuple': tf.io.FixedLenFeature([], tf.int64),\n  }\n  example = tf.io.parse_single_example(example, features)\n  img = tf.image.decode_image(example['img'])\n  img = tf.reshape(img, input_size + (1, ))\n  img = tf.cast(img, tf.float32)\n  # grayscale -> RGB\n  img = tf.repeat(img, 3, -1)\n\n  # image_id = tf.cast(example['image_id'], tf.int32)\n  # grapheme_root = tf.cast(example['grapheme_root'], tf.int32)\n  # vowel_diacritic = tf.cast(example['vowel_diacritic'], tf.int32)\n  # consonant_diacritic = tf.cast(example['consonant_diacritic'], tf.int32)\n  unique_tuple = tf.cast(example['unique_tuple'], tf.int32)\n  return img, unique_tuple","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--model_id', type=int, default=71)\n    parser.add_argument('--seed', type=int, default=123)\n    parser.add_argument('--lr', type=float, default=1e-4)\n    parser.add_argument('--input_size', type=str, default='160,256')\n    parser.add_argument('--batch_size', type=int, default=128)\n    parser.add_argument('--epochs', type=int, default=30)\n    parser.add_argument('--backbone', type=str, default='efficientnet-b4')\n    parser.add_argument('--weights', type=str, default='imagenet')\n    args, _ = parser.parse_known_args()\n\n    args.input_size = tuple(int(x) for x in args.input_size.split(','))\n    np.random.seed(args.seed)\n    tf.random.set_seed(args.seed)\n\n  # build the model\n    strategy = get_strategy()\n    with strategy.scope():\n        model = get_model(input_size=args.input_size + (3, ), backbone=args.backbone,\n        weights=args.weights)\n#         new_model = load_model('../input/efficenet-b4-30-epochs/model-0070.h5')\n    \n    model.load_weights('../input/efficenet-b4-30-epochs/model-0000.h5')\n    model.compile(optimizer=Adam(lr=args.lr),\n                loss=categorical_crossentropy,\n                metrics=[categorical_accuracy, top_k_categorical_accuracy])\n\n\n    AUTO = tf.data.experimental.AUTOTUNE #\n    ignore_order = tf.data.Options() #\n    ignore_order.experimental_deterministic = False #\n    \n    ds_path = KaggleDatasets().get_gcs_path('bengali-tfrecords-v010')\n    train_fns = tf.io.gfile.glob(os.path.join(ds_path, 'records/train*.tfrec'))\n    train_ds = tf.data.TFRecordDataset(train_fns, num_parallel_reads=AUTO)\n#     train_ds = train_ds.with_optional(ignore_order)\n    train_ds = train_ds.map(lambda e: read_tfrecords(e, args.input_size))\n    train_ds = train_ds.repeat().batch(args.batch_size)\n    train_ds = train_ds.map(one_hot)\n    train_ds = train_ds.map(lambda a, b: mixup(a, b, args.batch_size))\n    \n    val_fns = tf.io.gfile.glob(os.path.join(ds_path, 'records/val*.tfrec'))\n    val_ds = tf.data.TFRecordDataset(val_fns, num_parallel_reads=AUTO)\n#     val_ds = val_ds.with_optional(ignore_order)\n    val_ds = val_ds.map(lambda e: read_tfrecords(e, args.input_size))\n    val_ds = val_ds.batch(args.batch_size)\n    val_ds = val_ds.map(one_hot)\n\n  # train\n    num_train_samples = sum(int(fn.split('_')[2]) for fn in train_fns)\n     # num_val_samples = sum(int(fn.split('_')[2]) for fn in val_fns)\n    steps_per_epoch = num_train_samples // args.batch_size\n    print(f'Training on {num_train_samples} samples. Each epochs requires {steps_per_epoch} steps')\n    h = model.fit(train_ds, steps_per_epoch=steps_per_epoch, epochs=args.epochs, verbose=1,\n          validation_data=val_ds)\n    print(h)\n    weight_fn = 'model-%04d.h5' % args.model_id\n    model.save_weights(weight_fn)\n    model.save('model.h5')\n    print(f'Saved weights to: {weight_fn}')","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmain()","execution_count":20,"outputs":[{"output_type":"stream","text":"Running on TPU  ['10.0.0.2:8470']\nREPLICAS:  8\nUsing backbone efficientnet-b4 and weights imagenet\nDownloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b4_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n71892992/71892840 [==============================] - 3s 0us/step\n","name":"stdout"},{"output_type":"error","ename":"OSError","evalue":"Unable to open file (unable to open file: name = '../input/efficenet-b4-30-epochs/model-0070.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m<ipython-input-19-62a73c093053>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         new_model = load_model('../input/efficenet-b4-30-epochs/model-0070.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/efficenet-b4-30-epochs/model-0070.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     model.compile(optimizer=Adam(lr=args.lr),\n\u001b[1;32m     26\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    233\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1213\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   1214\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '../input/efficenet-b4-30-epochs/model-0070.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}]},{"metadata":{},"cell_type":"markdown","source":"> > [Model file](model-0000.h5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}