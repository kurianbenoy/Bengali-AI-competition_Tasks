{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from tensorflow.keras import layers as L\n",
    "\n",
    "\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image -= tf.constant([0.485 * 255, 0.456 * 255, 0.406 * 255])\n",
    "    image /= tf.constant([0.229 * 255, 0.224 * 255, 0.225 * 255])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, backbone='efficientnet-b0', weights='imagenet', tta=False):\n",
    "    print(f'Using backbone {backbone} and weights {weights}')\n",
    "    x = L.Input(shape=input_size, name='imgs', dtype='float32')\n",
    "    y = normalize(x)\n",
    "    \n",
    "    if backbone.startswith('efficientnet'):\n",
    "        model_fn = getattr(efn, f'EfficientNetB{backbone[-1]}')\n",
    "        \n",
    "    y = model_fn(input_shape=input_size, weights=weights, include_top=False)(y)\n",
    "    y = L.GlobalAveragePooling2D()(y)\n",
    "    y = L.Dropout(0.05)(y)\n",
    "    # 1292 out 1295 are present at bottom layer\n",
    "    y = L.BatchNormalization()(y)\n",
    "    y = L.Dense(1292, activation='softmax')(y)\n",
    "    model = tf.keras.Model(x, y)\n",
    "    \n",
    "    if tta:\n",
    "        assert False, 'This doesn not make sense'\n",
    "        x_flip = tf.reverse(x, [2])  # 'NHWC'\n",
    "        y_tta = tf.add(model(x), model(x_flip)) / 2.0\n",
    "        tta_model = tf.keras.Model(x, y_tta)\n",
    "        return model, tta_model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read mixup paper\n",
    "def mixup(img_batch, label_batch, bs):\n",
    "    weight = tf.random.uniform([bs])\n",
    "    x_weight = tf.reshape(weight, [bs,1,1,1])\n",
    "    y_weight = tf.reshape(weight, [bs,1])\n",
    "    index = tf.random.shuffle(tf.range(bs, dtype=tf.int32))\n",
    "    x1, x2 = img_batch, tf.gather(img_batch, index)\n",
    "    img_batch = x1* x_weight + x2*(1. - x_weight)\n",
    "    y1, y2 = label_batch, tf.gather(label_batch, index)\n",
    "    label_batch = y1* y_weight + y2*(1. - y_weight)\n",
    "    return img_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strategy():\n",
    "  # Detect hardware, return appropriate distribution strategy\n",
    "  try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "  except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "  if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "  else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "  print('REPLICAS: ', strategy.num_replicas_in_sync)\n",
    "  return strategy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(image, label):\n",
    "  label = tf.one_hot(label, 1292)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecords(example, input_size):\n",
    "  features = {\n",
    "      'img': tf.io.FixedLenFeature([], tf.string),\n",
    "      'image_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "      'grapheme_root': tf.io.FixedLenFeature([], tf.int64),\n",
    "      'vowel_diacritic': tf.io.FixedLenFeature([], tf.int64),\n",
    "      'consonant_diacritic': tf.io.FixedLenFeature([], tf.int64),\n",
    "      'unique_tuple': tf.io.FixedLenFeature([], tf.int64),\n",
    "  }\n",
    "  example = tf.io.parse_single_example(example, features)\n",
    "  img = tf.image.decode_image(example['img'])\n",
    "  img = tf.reshape(img, input_size + (1, ))\n",
    "  img = tf.cast(img, tf.float32)\n",
    "  # grayscale -> RGB\n",
    "  img = tf.repeat(img, 3, -1)\n",
    "\n",
    "  # image_id = tf.cast(example['image_id'], tf.int32)\n",
    "  # grapheme_root = tf.cast(example['grapheme_root'], tf.int32)\n",
    "  # vowel_diacritic = tf.cast(example['vowel_diacritic'], tf.int32)\n",
    "  # consonant_diacritic = tf.cast(example['consonant_diacritic'], tf.int32)\n",
    "  unique_tuple = tf.cast(example['unique_tuple'], tf.int32)\n",
    "  return img, unique_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "class LearningRateDecay:\n",
    "\tdef plot(self, epochs, title=\"Learning Rate Schedule\"):\n",
    "\t\t# compute the set of learning rates for each corresponding\n",
    "\t\t# epoch\n",
    "\t\tlrs = [self(i) for i in epochs]\n",
    "\t\t# the learning rate schedule\n",
    "\t\tplt.style.use(\"ggplot\")\n",
    "\t\tplt.figure()\n",
    "\t\tplt.plot(epochs, lrs)\n",
    "\t\tplt.title(title)\n",
    "\t\tplt.xlabel(\"Epoch #\")\n",
    "\t\tplt.ylabel(\"Learning Rate\")\n",
    "\n",
    "class StepDecay(LearningRateDecay):\n",
    "\tdef __init__(self, initAlpha=0.01, factor=0.25, dropEvery=10):\n",
    "\t\t# store the base initial learning rate, drop factor, and\n",
    "\t\t# epochs to drop every\n",
    "\t\tself.initAlpha = initAlpha\n",
    "\t\tself.factor = factor\n",
    "\t\tself.dropEvery = dropEvery\n",
    "\tdef __call__(self, epoch):\n",
    "\t\t# compute the learning rate for the current epoch\n",
    "\t\texp = np.floor((1 + epoch) / self.dropEvery)\n",
    "\t\talpha = self.initAlpha * (self.factor ** exp)\n",
    "\t\t# return the learning rate\n",
    "\t\treturn float(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_id', type=int, default=0)\n",
    "    parser.add_argument('--seed', type=int, default=123)\n",
    "    parser.add_argument('--lr', type=float, default=1e-4)\n",
    "    parser.add_argument('--input_size', type=str, default='160,256')\n",
    "    parser.add_argument('--batch_size', type=int, default=256)\n",
    "    parser.add_argument('--epochs', type=int, default=35)\n",
    "    parser.add_argument('--backbone', type=str, default='efficientnet-b4')\n",
    "    parser.add_argument('--weights', type=str, default='imagenet')\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    args.input_size = tuple(int(x) for x in args.input_size.split(','))\n",
    "    np.random.seed(args.seed)\n",
    "    tf.random.set_seed(args.seed)\n",
    "\n",
    "  # build the model\n",
    "    strategy = get_strategy()\n",
    "    with strategy.scope():\n",
    "        model = get_model(input_size=args.input_size + (3, ), backbone=args.backbone,\n",
    "        weights=args.weights)\n",
    "        schedule = StepDecay(initAlpha=1e-4, factor=0.25, dropEvery=15)\n",
    "        model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=[categorical_accuracy, top_k_categorical_accuracy])\n",
    "\n",
    "    callbacks = [LearningRateScheduler(schedule)]\n",
    "    AUTO = tf.data.experimental.AUTOTUNE #\n",
    "    ignore_order = tf.data.Options() #\n",
    "    ignore_order.experimental_deterministic = False #\n",
    "    \n",
    "    ds_path = KaggleDatasets().get_gcs_path('bengali-tfrecords-v010')\n",
    "    train_fns = tf.io.gfile.glob(os.path.join(ds_path, 'records/train*.tfrec'))\n",
    "    train_ds = tf.data.TFRecordDataset(train_fns, num_parallel_reads=AUTO)\n",
    "#     train_ds = train_ds.with_optional(ignore_order)\n",
    "    train_ds = train_ds.map(lambda e: read_tfrecords(e, args.input_size), num_parallel_calls=AUTO)\n",
    "    train_ds = train_ds.repeat().batch(args.batch_size)\n",
    "    train_ds = train_ds.map(one_hot)\n",
    "    train_ds = train_ds.map(lambda a, b: mixup(a, b, args.batch_size), num_parallel_calls=AUTO)\n",
    "    \n",
    "    val_fns = tf.io.gfile.glob(os.path.join(ds_path, 'records/val*.tfrec'))\n",
    "    val_ds = tf.data.TFRecordDataset(val_fns, num_parallel_reads=AUTO)\n",
    "#     val_ds = val_ds.with_optional(ignore_order)\n",
    "    val_ds = val_ds.map(lambda e: read_tfrecords(e, args.input_size), num_parallel_calls=AUTO)\n",
    "    val_ds = val_ds.batch(args.batch_size)\n",
    "    val_ds = val_ds.map(one_hot)\n",
    "\n",
    "  # train\n",
    "    num_train_samples = sum(int(fn.split('_')[2]) for fn in train_fns)\n",
    "     # num_val_samples = sum(int(fn.split('_')[2]) for fn in val_fns)\n",
    "    steps_per_epoch = num_train_samples // args.batch_size\n",
    "    print(f'Training on {num_train_samples} samples. Each epochs requires {steps_per_epoch} steps')\n",
    "    h = model.fit(train_ds, steps_per_epoch=steps_per_epoch, epochs=args.epochs, verbose=1,\n",
    "          validation_data=val_ds,callbacks=callbacks)\n",
    "    print(h)\n",
    "    weight_fn = 'model-%04d.h5' % args.model_id\n",
    "    model.save_weights(weight_fn)\n",
    "    model.save('Enet-final.h5')\n",
    "    print(f'Saved weights to: {weight_fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  ['10.0.0.2:8470']\n",
      "REPLICAS:  8\n",
      "Using backbone efficientnet-b4 and weights imagenet\n",
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b4_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "71892992/71892840 [==============================] - 3s 0us/step\n",
      "Training on 160672 samples. Each epochs requires 627 steps\n",
      "Train for 627 steps\n",
      "Epoch 1/35\n",
      "627/627 [==============================] - 271s 432ms/step - loss: 6.3533 - categorical_accuracy: 0.0598 - top_k_categorical_accuracy: 0.1523 - val_loss: 2.6894 - val_categorical_accuracy: 0.4261 - val_top_k_categorical_accuracy: 0.7541\n",
      "Epoch 2/35\n",
      "627/627 [==============================] - 128s 205ms/step - loss: 3.6755 - categorical_accuracy: 0.5016 - top_k_categorical_accuracy: 0.7596 - val_loss: 0.6694 - val_categorical_accuracy: 0.8622 - val_top_k_categorical_accuracy: 0.9778\n",
      "Epoch 3/35\n",
      "627/627 [==============================] - 127s 202ms/step - loss: 2.8867 - categorical_accuracy: 0.6793 - top_k_categorical_accuracy: 0.8704 - val_loss: 0.3635 - val_categorical_accuracy: 0.9242 - val_top_k_categorical_accuracy: 0.9892\n",
      "Epoch 4/35\n",
      "627/627 [==============================] - 126s 201ms/step - loss: 2.5358 - categorical_accuracy: 0.7224 - top_k_categorical_accuracy: 0.8965 - val_loss: 0.2556 - val_categorical_accuracy: 0.9438 - val_top_k_categorical_accuracy: 0.9927\n",
      "Epoch 5/35\n",
      "627/627 [==============================] - 127s 202ms/step - loss: 2.2807 - categorical_accuracy: 0.7367 - top_k_categorical_accuracy: 0.9079 - val_loss: 0.2044 - val_categorical_accuracy: 0.9545 - val_top_k_categorical_accuracy: 0.9948\n",
      "Epoch 6/35\n",
      "627/627 [==============================] - 126s 202ms/step - loss: 2.0858 - categorical_accuracy: 0.7415 - top_k_categorical_accuracy: 0.9159 - val_loss: 0.1789 - val_categorical_accuracy: 0.9599 - val_top_k_categorical_accuracy: 0.9955\n",
      "Epoch 7/35\n",
      "627/627 [==============================] - 127s 202ms/step - loss: 1.9272 - categorical_accuracy: 0.7471 - top_k_categorical_accuracy: 0.9266 - val_loss: 0.1680 - val_categorical_accuracy: 0.9618 - val_top_k_categorical_accuracy: 0.9959\n",
      "Epoch 8/35\n",
      "627/627 [==============================] - 127s 202ms/step - loss: 1.8017 - categorical_accuracy: 0.7518 - top_k_categorical_accuracy: 0.9334 - val_loss: 0.1414 - val_categorical_accuracy: 0.9666 - val_top_k_categorical_accuracy: 0.9964\n",
      "Epoch 9/35\n",
      "627/627 [==============================] - 127s 202ms/step - loss: 1.7060 - categorical_accuracy: 0.7574 - top_k_categorical_accuracy: 0.9409 - val_loss: 0.1378 - val_categorical_accuracy: 0.9681 - val_top_k_categorical_accuracy: 0.9968\n",
      "Epoch 10/35\n",
      "627/627 [==============================] - 126s 202ms/step - loss: 1.6244 - categorical_accuracy: 0.7600 - top_k_categorical_accuracy: 0.9472 - val_loss: 0.1228 - val_categorical_accuracy: 0.9702 - val_top_k_categorical_accuracy: 0.9972\n",
      "Epoch 11/35\n",
      "627/627 [==============================] - 127s 203ms/step - loss: 1.5582 - categorical_accuracy: 0.7632 - top_k_categorical_accuracy: 0.9521 - val_loss: 0.1182 - val_categorical_accuracy: 0.9710 - val_top_k_categorical_accuracy: 0.9972\n",
      "Epoch 12/35\n",
      "627/627 [==============================] - 128s 204ms/step - loss: 1.5039 - categorical_accuracy: 0.7653 - top_k_categorical_accuracy: 0.9560 - val_loss: 0.1120 - val_categorical_accuracy: 0.9723 - val_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 13/35\n",
      "627/627 [==============================] - 125s 200ms/step - loss: 1.4536 - categorical_accuracy: 0.7677 - top_k_categorical_accuracy: 0.9596 - val_loss: 0.1070 - val_categorical_accuracy: 0.9735 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 14/35\n",
      "627/627 [==============================] - 126s 201ms/step - loss: 1.4094 - categorical_accuracy: 0.7706 - top_k_categorical_accuracy: 0.9639 - val_loss: 0.1037 - val_categorical_accuracy: 0.9743 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 15/35\n",
      "627/627 [==============================] - 127s 202ms/step - loss: 1.3416 - categorical_accuracy: 0.7791 - top_k_categorical_accuracy: 0.9688 - val_loss: 0.0962 - val_categorical_accuracy: 0.9767 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 16/35\n",
      "627/627 [==============================] - 127s 202ms/step - loss: 1.3205 - categorical_accuracy: 0.7801 - top_k_categorical_accuracy: 0.9710 - val_loss: 0.0954 - val_categorical_accuracy: 0.9772 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 17/35\n",
      "627/627 [==============================] - 126s 201ms/step - loss: 1.3027 - categorical_accuracy: 0.7816 - top_k_categorical_accuracy: 0.9710 - val_loss: 0.0942 - val_categorical_accuracy: 0.9771 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 18/35\n",
      "627/627 [==============================] - 126s 201ms/step - loss: 1.2840 - categorical_accuracy: 0.7839 - top_k_categorical_accuracy: 0.9730 - val_loss: 0.0941 - val_categorical_accuracy: 0.9772 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 19/35\n",
      "627/627 [==============================] - 126s 201ms/step - loss: 1.2753 - categorical_accuracy: 0.7844 - top_k_categorical_accuracy: 0.9728 - val_loss: 0.0924 - val_categorical_accuracy: 0.9772 - val_top_k_categorical_accuracy: 0.9978\n",
      "Epoch 20/35\n",
      "627/627 [==============================] - 127s 202ms/step - loss: 1.2058 - categorical_accuracy: 0.7866 - top_k_categorical_accuracy: 0.9777 - val_loss: 0.0889 - val_categorical_accuracy: 0.9782 - val_top_k_categorical_accuracy: 0.9978\n",
      "Epoch 28/35\n",
      "627/627 [==============================] - 125s 200ms/step - loss: 1.1753 - categorical_accuracy: 0.7902 - top_k_categorical_accuracy: 0.9801 - val_loss: 0.0845 - val_categorical_accuracy: 0.9797 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 32/35\n",
      "627/627 [==============================] - 125s 200ms/step - loss: 1.1598 - categorical_accuracy: 0.7933 - top_k_categorical_accuracy: 0.9811 - val_loss: 0.0840 - val_categorical_accuracy: 0.9793 - val_top_k_categorical_accuracy: 0.9981\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7f43efa54198>\n",
      "Saved weights to: model-0000.h5\n",
      "CPU times: user 16min 44s, sys: 1min 7s, total: 17min 51s\n",
      "Wall time: 1h 17min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
